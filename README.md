# ğŸ“„ Text Summarizer App

An end-to-end text summarization application that leverages Hugging Face's PEGASUS model to summarize long conversational text. It includes data ingestion, preprocessing, model training, evaluation, and an interactive Streamlit interface for real-time inference.

---

## ğŸ”§ Key Features

- **Model Used**: PEGASUS from Hugging Face Transformers
- **Pipeline**:
  - Data Ingestion
  - Data Transformation
  - Model Training
  - Model Evaluation
  - Inference with Streamlit frontend and FastAPI backend
- **Trained On**: SAMSum dataset (for dialogue summarization)
- **Evaluation Metrics**: ROUGE-1, ROUGE-2, ROUGE-L, ROUGE-Lsum
- **Frontend**: Streamlit
- **Backend**: FastAPI

---

## ğŸ”¹ Project Structure

```
â”œâ”€â”€ config/                  # YAML config files for pipeline and parameters
â”œâ”€â”€ src/textSummarizer/
â”‚   â”œâ”€â”€ components/          # Core steps: ingestion, transformation, trainer, evaluation
â”‚   â”œâ”€â”€ pipeline/            # Pipelines to execute each stage
â”‚   â”œâ”€â”€ config/              # Configuration manager
â”‚   â”œâ”€â”€ entity/              # Pydantic-style configuration schemas
â”‚   â”œâ”€â”€ utils/               # Helpers for YAML reading and directory creation
â”‚   â””â”€â”€ logging/             # Logger setup
â”œâ”€â”€ research/                # Notebooks for experimentation
â”œâ”€â”€ streamlit_app.py         # Streamlit frontend for interactive summarization
â”œâ”€â”€ app.py                   # FastAPI backend
â”œâ”€â”€ requirements.txt         # Dependencies
```

---

## â™»ï¸ Workflow Overview

### 1. âš™ï¸ Configuration Manager (`config/configuration.py`)
- Reads paths and parameters from YAML files
- Returns structured configs to each pipeline stage

### 2. ğŸ“ Data Ingestion (`components/data_ingestion.py`)
- Downloads SAMSum dataset zip from URL
- Extracts it into the working directory

### 3. ğŸ¨ Data Transformation (`components/data_transformation.py`)
- Loads dataset using HuggingFace Datasets
- Tokenizes inputs and targets with `AutoTokenizer`
- Converts to model-compatible format

### 4. ğŸ† Model Training (`components/model_trainer.py`)
- Loads PEGASUS model
- Fine-tunes it using `Trainer`
- Saves model and tokenizer to disk

### 5. âš–ï¸ Model Evaluation (`components/model_evaluation.py`)
- Loads trained model and tokenizer
- Evaluates on ROUGE metrics using `evaluate` package
- Saves results to CSV

### 6. ğŸš€ Inference (`pipeline/prediction_pipeline.py`)
- Loads trained model/tokenizer
- Predicts summary for given input text
- Used by both FastAPI and Streamlit

---

## ğŸšª How to Run

### âš¡ Step-by-Step
```bash
# 1. Clone the repo
$ git clone <your-repo-url>
$ cd text_summarizer

# 2. Create virtual environment
$ python -m venv venv && source venv/bin/activate

# 3. Install requirements
$ pip install -r requirements.txt

# 4. Run backend (for Streamlit to call)
$ uvicorn app:app --reload

# 5. Run the frontend
$ streamlit run streamlit_app.py
```

### ğŸŒ Streamlit App Preview
- Input: Conversational dialogue
- Output: Concise summary generated by the model

---

## ğŸ“Š Example Usage

Input:
```
A: I need to book a flight to Toronto next Monday.
B: Morning or afternoon?
A: Afternoon is better. Maybe around 3 PM.
```

Summary:
> "User wants to book a flight to Toronto on Monday afternoon around 3 PM."

---

## ğŸš« Troubleshooting
- `torch==2.0.1` may fail on Python 3.12. Use a compatible version or update it to `torch>=2.2.0`
- Avoid conflicting Streamlit versions (`1.30.0` vs `1.32.2`) in `requirements.txt`
- Ensure model and tokenizer paths are valid before evaluation/inference

---

## ğŸ“ Credits
- Hugging Face Transformers
- Streamlit + FastAPI
- SAMSum dataset authors

---

## ğŸš€ Future Work
- Add support for other models (T5, BART)
- Host on Hugging Face or Streamlit Cloud
- Add feedback loop to fine-tune model with user corrections

---

## âœ… License
MIT License. See `LICENSE` file.

---

## ğŸ“¢ Author
**Mustafa Tark**  
Feel free to reach out for feedback or collaboration!


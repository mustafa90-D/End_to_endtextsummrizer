# 📄 Text Summarizer App

An end-to-end text summarization application that leverages Hugging Face's PEGASUS model to summarize long conversational text. It includes data ingestion, preprocessing, model training, evaluation, and an interactive Streamlit interface for real-time inference.

---

## 🔧 Key Features

- **Model Used**: PEGASUS from Hugging Face Transformers
- **Pipeline**:
  - Data Ingestion
  - Data Transformation
  - Model Training
  - Model Evaluation
  - Inference with Streamlit frontend and FastAPI backend
- **Trained On**: SAMSum dataset (for dialogue summarization)
- **Evaluation Metrics**: ROUGE-1, ROUGE-2, ROUGE-L, ROUGE-Lsum
- **Frontend**: Streamlit
- **Backend**: FastAPI

---

## 🔹 Project Structure

```
├── config/                  # YAML config files for pipeline and parameters
├── src/textSummarizer/
│   ├── components/          # Core steps: ingestion, transformation, trainer, evaluation
│   ├── pipeline/            # Pipelines to execute each stage
│   ├── config/              # Configuration manager
│   ├── entity/              # Pydantic-style configuration schemas
│   ├── utils/               # Helpers for YAML reading and directory creation
│   └── logging/             # Logger setup
├── research/                # Notebooks for experimentation
├── streamlit_app.py         # Streamlit frontend for interactive summarization
├── app.py                   # FastAPI backend
├── requirements.txt         # Dependencies
```

---

## ♻️ Workflow Overview

### 1. ⚙️ Configuration Manager (`config/configuration.py`)
- Reads paths and parameters from YAML files
- Returns structured configs to each pipeline stage

### 2. 📁 Data Ingestion (`components/data_ingestion.py`)
- Downloads SAMSum dataset zip from URL
- Extracts it into the working directory

### 3. 🎨 Data Transformation (`components/data_transformation.py`)
- Loads dataset using HuggingFace Datasets
- Tokenizes inputs and targets with `AutoTokenizer`
- Converts to model-compatible format

### 4. 🏆 Model Training (`components/model_trainer.py`)
- Loads PEGASUS model
- Fine-tunes it using `Trainer`
- Saves model and tokenizer to disk

### 5. ⚖️ Model Evaluation (`components/model_evaluation.py`)
- Loads trained model and tokenizer
- Evaluates on ROUGE metrics using `evaluate` package
- Saves results to CSV

### 6. 🚀 Inference (`pipeline/prediction_pipeline.py`)
- Loads trained model/tokenizer
- Predicts summary for given input text
- Used by both FastAPI and Streamlit

---

## 🚪 How to Run

### ⚡ Step-by-Step
```bash
# 1. Clone the repo
$ git clone <your-repo-url>
$ cd text_summarizer

# 2. Create virtual environment
$ python -m venv venv && source venv/bin/activate

# 3. Install requirements
$ pip install -r requirements.txt

# 4. Run backend (for Streamlit to call)
$ uvicorn app:app --reload

# 5. Run the frontend
$ streamlit run streamlit_app.py
```

### 🌐 Streamlit App Preview
- Input: Conversational dialogue
- Output: Concise summary generated by the model

---

## 📊 Example Usage

Input:
```
A: I need to book a flight to Toronto next Monday.
B: Morning or afternoon?
A: Afternoon is better. Maybe around 3 PM.
```

Summary:
> "User wants to book a flight to Toronto on Monday afternoon around 3 PM."

---

## 🚫 Troubleshooting
- `torch==2.0.1` may fail on Python 3.12. Use a compatible version or update it to `torch>=2.2.0`
- Avoid conflicting Streamlit versions (`1.30.0` vs `1.32.2`) in `requirements.txt`
- Ensure model and tokenizer paths are valid before evaluation/inference

---

## 🎓 Credits
- Hugging Face Transformers
- Streamlit + FastAPI
- SAMSum dataset authors

---

## 🚀 Future Work
- Add support for other models (T5, BART)
- Host on Hugging Face or Streamlit Cloud
- Add feedback loop to fine-tune model with user corrections

---

## ✅ License
MIT License. See `LICENSE` file.

---

## 📢 Author
**Mustafa Tark**  
Feel free to reach out for feedback or collaboration!

